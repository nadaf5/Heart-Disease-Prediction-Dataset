{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Heart Disease Dataset: Clinical Features for Predicting Heart Disease Presence**"
      ],
      "metadata": {
        "id": "Z39qS7Z6AXRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import kagglehub  #downloading dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# imports i used Supervised learning models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# for Evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# imports i used Unsupervised learning and dimensionality reduction\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "5sQapbyNebHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfRvfn5QxJPI"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"johnsmith88/heart-disease-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"johnsmith88/heart-disease-dataset\")\n",
        "csv_path = os.path.join(path, \"heart.csv\")\n",
        "\n",
        "# Load dataset into df\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# print\n",
        "print(\"Data loaded successfully! Shape:\", df.shape)\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "bMWFslSO4ZR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View column info and data types\n",
        "df.info()\n",
        "\n",
        "# Statistical summary of numerical features\n",
        "df.describe()\n",
        "\n",
        "# Check for missing values\n",
        "df.isnull().sum()\n",
        "\n",
        "# Check for duplicate rows\n",
        "df.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "NLOHaI6b7c16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(' the Dataset Description is :')\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "wrjZQWiZkZJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Training set shape:\", X_train_scaled.shape)\n",
        "print(\"Testing set shape:\", X_test_scaled.shape)"
      ],
      "metadata": {
        "id": "Nr_pTFma4L8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Supervised Learning** using Classification by Logistic regression"
      ],
      "metadata": {
        "id": "FwPnBFSV7zsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance from the trained model\n",
        "feature_importance = lr.coef_[0]  # using lr\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(feature_importance)), feature_importance, color='lightgreen')\n",
        "plt.xlabel('Feature Index')\n",
        "plt.ylabel('Importance (Coefficient Value)')\n",
        "plt.title('Feature Importance using Logistic Regression')\n",
        "plt.show()  # correctly displays the plot\n"
      ],
      "metadata": {
        "id": "1wkDOb9GfzYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Using Naive Bayes:"
      ],
      "metadata": {
        "id": "3FlD6Ow6Qg3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Fixing the target name\n",
        "df.rename(columns={'num': 'target', 'output': 'target'}, inplace=True)\n",
        "\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "# now will Split and scale the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Training Naive Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "# The Results:\n",
        "print(\"Naive Bayes Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "L_8JcoWwECyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Correlation Heatmap"
      ],
      "metadata": {
        "id": "ccKBNvUbeLDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "corr = df.corr()  # Correlation matrix\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kQpH-LVWeCou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Unsupervised Learning** using Clustering K-means"
      ],
      "metadata": {
        "id": "J9IZ6oFL8RYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  K-Means Clustering with counts and contingency table\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Features only no target\n",
        "X = df.drop(columns=['target'])\n",
        "\n",
        "# Step 1: Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 2: Apply K-Means with 2 clusters\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Step 3: Add cluster labels to dataset\n",
        "df['Cluster'] = clusters\n",
        "\n",
        "# Step 4: Cluster label counts\n",
        "print(\"Cluster label counts:\")\n",
        "print(df['Cluster'].value_counts())\n",
        "\n",
        "# Step 5: Contingency table: clusters vs target\n",
        "print(\"\\nContingency Table (Cluster vs Target):\")\n",
        "print(pd.crosstab(df['Cluster'], df['target']))\n",
        "\n",
        "# Step 6: PCA for 2D visualization\n",
        "X_pca = PCA(n_components=2).fit_transform(X_scaled)\n",
        "\n",
        "# Step 7: Colors pink & blue for clusters\n",
        "colors = ['pink' if label == 0 else 'blue' for label in clusters]\n",
        "\n",
        "# Step 8: Plot clusters in 2D\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(X_pca[:,0], X_pca[:,1], c=colors, edgecolor='k', s=50)\n",
        "plt.xlabel('PC 1')\n",
        "plt.ylabel('PC 2')\n",
        "plt.title('K-Means Clustering of Heart Disease Data (2D PCA)')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "KAXgYghdAwdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i will Choose number for the clusters (k)let say for ex =2\n",
        "k_choice = 2\n",
        "\n",
        "# Fit K-Means with chosen k\n",
        "kmeans = KMeans(n_clusters=k_choice, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels to dataset\n",
        "df['Cluster'] = clusters\n",
        "\n",
        "# Cluster label counts\n",
        "print(f\"Cluster label counts (k={k_choice}):\")\n",
        "print(df['Cluster'].value_counts())\n",
        "\n",
        "# Contingency table: clusters vs target\n",
        "print(\"\\nContingency Table (Cluster vs Target):\")\n",
        "print(pd.crosstab(df['Cluster'], df['target']))\n"
      ],
      "metadata": {
        "id": "EzOGeJzNDfmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dimensionality Reduction (PCA)\n"
      ],
      "metadata": {
        "id": "gSfqrvEiAr8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"johnsmith88/heart-disease-dataset\")\n",
        "df = pd.read_csv(os.path.join(path, \"heart.csv\"))\n",
        "df.rename(columns={'num':'target','output':'target'}, inplace=True)\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Standardize and apply PCA\n",
        "X_pca = PCA(n_components=2).fit_transform(StandardScaler().fit_transform(X))\n",
        "\n",
        "# i Maped target values to colors: 0 = will be green (no disease), and 1 = light red (disease)\n",
        "colors = ['green' if val==0 else 'lightcoral' for val in y]\n",
        "\n",
        "# Plot PCA with custom colors\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(X_pca[:,0], X_pca[:,1], c=colors, edgecolor='k', s=50)\n",
        "plt.xlabel('PC 1')\n",
        "plt.ylabel('PC 2')\n",
        "plt.title('Heart Disease PCA in 2D Projection')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-IfHIngkFNWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Summery Report:**\n",
        "\n",
        "In this Assigment , i analyzed the Heart Disease Dataset from Kaggle to predict the presence of heart disease and explore patterns in the data. First, we conducted an initial examination, checking the datasetâ€™s structure, data types, statistical summaries, and ensuring there were no missing or duplicate entries.\n",
        "\n",
        "Features and target were separated for analysis (X for features, y for target).\n",
        "\n",
        "1. Then we used **Supervised learning**:\n",
        "I Applied Logistic Regression and Naive Bayes classifiers\n",
        "\n",
        "in **Logistic Regression**\n",
        "Train/test split: 80/20, features scaled.\n",
        "Accuracy: 80%, balanced precision and recall.\n",
        "Feature importance shown in a light green bar chart.\n",
        "and in **Naive Bayes**\n",
        "Same split and scaling.\n",
        "But, the Accuracy: 78 - 80%, reasonable predictive performance.\n",
        "\n",
        "2. In **unsupervised learning**, I performed K-Means clustering with two clusters, evaluated cluster label counts, and generated a contingency table comparing clusters to the actual target.\n",
        "\n",
        "so the Cluster label counts displayed.\n",
        "and the Contingency table comparing clusters to actual target shows relationship patterns.\n",
        "additonaly to the 2D Visualization:\n",
        "PCA used to reduce (dimensions to 2).\n",
        "Clusters are plotted with pink and blue for visualization.\n",
        "\n",
        "\n",
        "3. lastley, **Dimensionality Reduction PCA** is applied :\n",
        "PCA applied to the dataset for 2D projection.\n",
        "Visualization:\n",
        "Patients without disease are in green, with disease in light red.\n",
        "Clear separation patterns observed, supporting clustering and classification insights.\n",
        "\n",
        "To sum up: Successfully implemented supervised (Logistic Regression, Naive Bayes) and unsupervised (K-Means) learning.\n",
        "Feature scaling and PCA improved visualization and model performance.\n",
        "Clustering results complemented supervised models by revealing patterns in the data.\n",
        "Overall, the analysis demonstrates accurate predictions and interpretable insights into heart disease risk factors.\n"
      ],
      "metadata": {
        "id": "j2wXUOeUfJ-H"
      }
    }
  ]
}